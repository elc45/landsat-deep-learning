{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":24678,"status":"ok","timestamp":1701834818671,"user":{"displayName":"Eliot Carlson","userId":"09784583716339913528"},"user_tz":300},"id":"1B9b2g4khchN"},"outputs":[],"source":["import os\n","import ee\n","import random\n","import torch\n","import timm\n","import pickle\n","import numpy as np\n","import torch.nn as nn\n","import torchgeo\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader\n","from torchgeo.datasets import RasterDataset, Landsat8\n","from torchgeo.models import ResNet18_Weights\n","from torchgeo.samplers import RandomGeoSampler\n","from torchvision import transforms\n","from datetime import datetime"]},{"cell_type":"markdown","metadata":{},"source":["GEE Python API to extract images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bbAIyKn2Riqh"},"outputs":[],"source":["ee.Authenticate()\n","ee.Initialize()\n","\n","# Define arbitrary ROI in upstate New York for seasonality\n","roi = ee.Geometry.Rectangle([-74.8, 43.5, -74, 44])\n","\n","def get_image_collection(month, year, start_day, end_day):\n","    return ee.ImageCollection('LANDSAT/LC08/C02/T1') \\\n","        .filterBounds(roi) \\\n","        .filterDate(f'{year}-{month:02d}-{start_day:02d}', f'{year}-{month:02d}-{end_day:02d}') \\\n","        .sort('CLOUD_COVER_LAND') \\\n","        .limit(2)\n","\n","#Define months and years (handpicked for optimal cloudcover)\n","months_years = [\n","    (1, 2018, 1, 30), (2, 2019, 1, 28), (3, 2021, 1, 28), \n","    (4, 2020, 1, 28), (5, 2020, 1, 28), (6, 2020, 1, 30), \n","    (7, 2020, 1, 30), (8, 2020, 1, 30), (9, 2019, 1, 30), \n","    (10, 2021, 1, 30), (11, 2019, 1, 30), (12, 2019, 1, 30)\n","]\n","\n","def export_image_to_cloud(image, description):\n","    task = ee.batch.Export.image.toCloudStorage(\n","        image=image,\n","        description=description,\n","        bucket='dlcv_finalproj_data1',\n","        fileNamePrefix=f'imgcollect/{description}',\n","        scale=30,\n","        region=image.geometry().bounds(),\n","        fileFormat='GeoTIFF'\n","    )\n","    task.start()\n","\n","def get_and_export_images(image_collection):\n","    image_collection.select('B.+')\n","    image_ids = image_collection.aggregate_array('system:index').getInfo()\n","    \n","    for image_id in image_ids:\n","        image = image_collection.filter(ee.Filter.eq('system:index', image_id)).first()\n","        export_image_to_cloud(image, image_id)\n","\n","for month, year, start_day, end_day in months_years:\n","    image_collection = get_image_collection(month, year, start_day, end_day)\n","    get_and_export_images(image_collection)"]},{"cell_type":"markdown","metadata":{},"source":["Mount preprocessed (randomly sampled, mixed) image patches from Google Cloud Storage. For data any larger we'd need to load batches directly from bucket."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5UfCJWNGzoT-"},"outputs":[],"source":["bucket_name = 'dlcv_finalproj_data1'\n","folder_path = 'imgcollect'\n","file_path = 'combined_data.pkl'\n","\n","!gsutil -m -o 'gsutil:sliced_object_download_threshold=150M' cp -r gs://{bucket_name}/{file_path} /content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cGG0bo8VaPBi"},"outputs":[],"source":["with open(\"/content/combined_data.pkl\", 'rb') as file:\n","    data = pickle.load(file)\n","\n","random.shuffle(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQ5b3qYGbNWI"},"outputs":[],"source":["train_data = data[:10000]\n","val_data = data[10001:11250]\n","test_data = data[11250:]\n","\n","train_loader = DataLoader(train_data, batch_size=64)\n","val_loader = DataLoader(val_data, batch_size=64)\n","test_loader = DataLoader(test_data, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-qgDaMx6M1zs"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["Import Resnet18 pretrained Landsat weights; freeze backbone for first round training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v43e7jCVYXNY"},"outputs":[],"source":["weights = ResNet18_Weights.LANDSAT_OLI_SR_MOCO\n","in_chans = weights.meta[\"in_chans\"]\n","model = timm.create_model(\"resnet18\", in_chans=in_chans, num_classes=12)\n","model.load_state_dict(weights.get_state_dict(progress=True), strict=False)\n","model = model.to(device)\n","\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","for param in model.fc.parameters():\n","    param.requires_grad = True\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9UhjooVNrQBP"},"outputs":[],"source":["epoch = 0\n","val_accuracy = 0.0\n","\n","while val_accuracy < 96:\n","      epoch += 1\n","      model.train()\n","      running_loss = 0.0\n","\n","      for inputs, labels in train_loader:\n","          inputs, labels = inputs.to(device), labels.to(device)\n","          optimizer.zero_grad()\n","\n","          outputs = model(inputs).to(device)\n","          labels -= 1\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          running_loss += loss.item()\n","\n","      # Validate\n","      val_loss = 0.0\n","      correct = 0\n","      total = 0\n","      model.eval()\n","\n","      for inputs, labels in val_loader:\n","          inputs, labels = inputs.to(device), labels.to(device)\n","          labels -= 1\n","          outputs = model(inputs).to(device)\n","          loss = criterion(outputs, labels)\n","          val_loss += loss.item()\n","          _,predicted = torch.max(outputs,1)\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","\n","      #Calculate Performance\n","      val_loss /= len(val_loader)\n","      val_accuracy = 100 * (correct / total)\n","\n","      print(f'Epoch {epoch}, Train Loss: {running_loss / len(train_loader)}, Val Accuracy: {val_accuracy:.2f}%')\n","\n","best_weights = model.state_dict()\n","torch.save(best_weights, 'first_round_train.pth')"]},{"cell_type":"markdown","metadata":{},"source":["Unfreeze backbone"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lB_4ilA4gJqW"},"outputs":[],"source":["for param in model.parameters():\n","    param.requires_grad = True\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":127331,"status":"ok","timestamp":1701487623948,"user":{"displayName":"Eliot Carlson","userId":"09784583716339913528"},"user_tz":300},"id":"sSZlSvJ-gNt9","outputId":"492f3145-c48a-4ac6-cce5-6355cf45dfce"},"outputs":[],"source":["epoch = 0\n","val_accuracy = 0.0\n","\n","while val_accuracy < 98:\n","      epoch += 1\n","      model.train()\n","      running_loss = 0.0\n","\n","      for inputs, labels in train_loader:\n","          inputs, labels = inputs.to(device), labels.to(device)\n","          optimizer.zero_grad()\n","\n","          outputs = model(inputs).to(device)\n","          labels -= 1\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          running_loss += loss.item()\n","\n","      # Validate\n","      val_loss = 0.0\n","      correct = 0\n","      total = 0\n","      model.eval()\n","\n","      for inputs, labels in val_loader:\n","          inputs, labels = inputs.to(device), labels.to(device)\n","          labels -= 1\n","          outputs = model(inputs).to(device)\n","          loss = criterion(outputs, labels)\n","          val_loss += loss.item()\n","          _,predicted = torch.max(outputs,1)\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","\n","      #Calculate Performance\n","      val_loss /= len(val_loader)\n","      val_accuracy = 100 * (correct / total)\n","\n","      print(f'Epoch {epoch}, Train Loss: {running_loss / len(train_loader)}, Val Accuracy: {val_accuracy:.2f}%')\n","\n","best_weights = model.state_dict()\n","torch.save(best_weights, 'best_model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0nNSEvO0jzHr"},"outputs":[],"source":["model.eval()\n","\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","  for inputs, labels in test_loader:\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    outputs = model(inputs).to(device)\n","    _, predicted = torch.max(outputs,1)\n","    total += labels.size(0)\n","    labels -= 1\n","    correct += (predicted == labels).sum().item()\n","\n","accuracy = 100 * (correct / total)\n","print(f'Test Accuracy: {accuracy:.2f}%')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
